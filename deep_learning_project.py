# -*- coding: utf-8 -*-
"""Deep Learning Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16m_PVL7UaYHX-nKDQ1hna10H2tMLDihs
"""

import numpy as np
import tensorflow as tf
from tensorflow.keras.applications import vgg19
from tensorflow.keras.preprocessing import image as kp_image
from tensorflow.keras import Model
import matplotlib.pyplot as plt

def deprocess_image(processed_img):
    x = processed_img.numpy()
    # Perform reverse preprocessing to convert the image back to the original format
    x[:, :, 0] += 103.939
    x[:, :, 1] += 116.779
    x[:, :, 2] += 123.68
    x = x[:, :, ::-1]  # Convert from BGR to RGB
    x = np.clip(x, 0, 255).astype('uint8')
    return x

# Define the dimensions of the generated image
height = 256  # Adjust this value based on your input image height
width = 256   # Adjust this value based on your input image width

# Load pre-trained VGG19 model
vgg = vgg19.VGG19(include_top=False, weights='imagenet')
vgg.trainable = False

# Content layer and style layers
content_layers = ['block5_conv2']
style_layers = ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1', 'block5_conv1']

# Function to build the model
def get_model(content_layers, style_layers):
    vgg.trainable = False
    outputs = [vgg.get_layer(layer).output for layer in (content_layers + style_layers)]
    model = Model(inputs=[vgg.input], outputs=outputs)
    return model

# Function to preprocess image
def preprocess_image(image_path):
    img = kp_image.load_img(image_path, target_size=(224, 224))
    img = kp_image.img_to_array(img)
    img = np.expand_dims(img, axis=0)
    img = vgg19.preprocess_input(img)
    return img

def calculate_mse(original_image, generated_image):
    return tf.reduce_mean(tf.square(original_image - generated_image))

def calculate_mos(generated_image, human_rating):
    return human_rating

# Load content and style images
content_path = 'content.jpg'
style_path = 'style.jpg'
content_image = preprocess_image(content_path)
style_image = preprocess_image(style_path)

# Build the model
model = get_model(content_layers, style_layers)

# Define layer names
layer_names = ['block5_conv2']

# Define your loss functions
def calculate_content_loss(content_features, generated_features):
    generated_features_resized = tf.image.resize(generated_features, tf.shape(content_features)[1:3])
    return tf.reduce_mean(tf.square(content_features - generated_features_resized))

def gram_matrix(input_tensor):
    result = tf.linalg.einsum('bijc,bijd->bcd', input_tensor, input_tensor)
    input_shape = tf.shape(input_tensor)
    num_locations = tf.cast(input_shape[1]*input_shape[2], tf.float32)
    return result / num_locations

def calculate_style_loss(style_targets, generated_features):
    style_loss = 0
    for target, gen in zip(style_targets, generated_features):
        target_gram = gram_matrix(target)
        gen_gram = gram_matrix(gen)
        style_loss += tf.reduce_mean(tf.square(target_gram - gen_gram))
    return style_loss

def calculate_total_variation_loss(image):
    x_diff = image[:, :, 1:, :] - image[:, :, :-1, :]
    y_diff = image[:, 1:, :, :] - image[:, :-1, :, :]
    return tf.reduce_sum(tf.abs(x_diff)) + tf.reduce_sum(tf.abs(y_diff))

# Define weights for content, style, and total variation loss
content_weight = 1e3
style_weight = 1e-2
total_variation_weight = 1e-4

# Initialize generated image with content image
generated_image = tf.Variable(content_image)

# Define optimizer
learning_rate = 0.001  # Adjust this value based on your specific task and model
optimizer = tf.optimizers.Adam(learning_rate=learning_rate, beta_1=0.99, epsilon=1e-1)

# Define your train_step function
def train_step(generated_image, content_target, style_targets):
    with tf.GradientTape() as tape:
        # Forward pass
        outputs = model(generated_image)
        content_features = outputs[0]  # Assuming content layer is the first one
        style_features = outputs[1:]   # Style features start from the second one

        # Calculate content loss
        content_loss_val = calculate_content_loss(content_features, content_target)

        # Calculate style loss
        style_loss_val = calculate_style_loss(style_targets, style_features)

        # Total variation loss
        tv_loss = calculate_total_variation_loss(generated_image)

        # Total loss
        total_loss = content_weight * content_loss_val + style_weight * style_loss_val + total_variation_weight * tv_loss

    # Compute gradients
    gradients = tape.gradient(total_loss, generated_image)

    # Update generated image
    optimizer.apply_gradients([(gradients, generated_image)])

    return total_loss

# Calculate MSE
mse = calculate_mse(content_image, generated_image)

# Calculate MOS
# Let's assume the human rating is 4.5 for demonstration purposes
human_rating = 4.5
mos = calculate_mos(generated_image, human_rating)

print("Mean Squared Error:", mse.numpy())
print("Mean Opinion Score:", mos)

# Main optimization loop
content_target = model(content_image)[0]
style_targets = [model(style_image)[i] for i in range(1, len(style_layers) + 1)]  # Skip content layer

mse_values = []
mos_values = []
for i in range(1000):
    loss = train_step(generated_image, content_target, style_targets)
    if i % 100 == 0:
        mse = calculate_mse(content_image, generated_image)
        human_rating = 4.5  # Placeholder for human rating, replace it with actual data
        mos = calculate_mos(generated_image, human_rating)

        print("Iteration:", i, "Loss:", loss.numpy(), "MSE:", mse.numpy(), "MOS:", mos)

        mse_values.append(mse.numpy())
        mos_values.append(mos)

# Plot MSE and MOS over iterations
plt.figure(figsize=(10, 5))
plt.plot(range(0, 1000, 100), mse_values, label='MSE')
plt.plot(range(0, 1000, 100), mos_values, label='MOS')
plt.xlabel('Iterations')
plt.ylabel('Value')
plt.title('MSE and MOS over iterations')
plt.legend()
plt.grid(True)
plt.show()

# Plot the result
plt.imshow(deprocess_image(tf.squeeze(generated_image, axis=0)))
plt.axis('off')
plt.show()